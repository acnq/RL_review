{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC and A2C: Actor_Critic (AC) algorithm\n",
    "\n",
    "将REINFORCE中估计$Q(s, a)$的MC方法替换为神经网络\n",
    "\n",
    "用td误差训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# 定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "  \n",
    "  def __init__(self):\n",
    "    env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "    super().__init__(env)\n",
    "    self.env = env\n",
    "    self.step_n = 0\n",
    "    \n",
    "  def reset(self):\n",
    "    state, _ = self.env.reset()\n",
    "    self.step_n = 0\n",
    "    return state\n",
    "  \n",
    "  def step(self, action):\n",
    "    state, reward, terminated, truncated, info = self.env.step(action)\n",
    "    over = terminated or truncated\n",
    "\n",
    "    #限制最大步数\n",
    "    self.step_n += 1\n",
    "    if self.step_n >= 200:\n",
    "        over = True\n",
    "    \n",
    "    #没坚持到最后,扣分\n",
    "    if over and self.step_n < 200:\n",
    "        reward = -1000\n",
    "\n",
    "    return state, reward, over\n",
    "  \n",
    "  # 打印游戏图像\n",
    "  def show(self):\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(self.env.render())\n",
    "    plt.show()\n",
    "    \n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "   (5): Softmax(dim=1)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\t\n",
    "# 演员模型：计算动作概率\n",
    "model_actor = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 2),\n",
    "\ttorch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "# 评委模型：计算每个动作价值\n",
    "model_critic = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay.load_state_dict(model_critic.state_dict())\n",
    "\n",
    "model_actor, model_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-986.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "\tstate = []\n",
    "\taction = []\n",
    "\treward = []\n",
    "\tnext_state = []\n",
    "\tover = []\n",
    "\n",
    "\ts = env.reset()\n",
    "\to = False\n",
    "\twhile not o:\n",
    "\t\t# 根据环境采样\n",
    "\t\tprob = model_actor(torch.FloatTensor(s).reshape(1, 4))[0].tolist()\n",
    "\t\ta = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\t\t\n",
    "\t\tns, r, o = env.step(a)\n",
    "\n",
    "\t\tstate.append(s)\n",
    "\t\taction.append(a)\n",
    "\t\treward.append(r)\n",
    "\t\tnext_state.append(ns)\n",
    "\t\tover.append(o)\n",
    "  \n",
    "\t\ts = ns\n",
    "\n",
    "\t\tif show:\n",
    "\t\t\tdisplay.clear_output(wait=True)\n",
    "\t\t\tenv.show()\n",
    "  \n",
    "\tstate = torch.FloatTensor(state).reshape(-1, 4)\n",
    "\taction = torch.LongTensor(action).reshape(-1, 1)\n",
    "\treward = torch.FloatTensor(reward).reshape(-1, 1)\n",
    "\tnext_state = torch.FloatTensor(next_state).reshape(-1, 4)\n",
    "\tover = torch.LongTensor(over).reshape(-1, 1)\n",
    "\n",
    "\treturn state, action, reward, next_state, over, reward.sum().item()\n",
    "\n",
    "state, action, reward, next_state, over, reward_sum = play()\n",
    "\n",
    "reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor = torch.optim.Adam(model_actor.parameters(), lr=4e-3)\n",
    "optimizer_critic = torch.optim.Adam(model_critic.parameters(), lr=4e-2)\n",
    "\n",
    "def requires_grad(model, value):\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad_(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# critic 模型训练\n",
    "def train_critic(state, reward, next_state, over):\n",
    "  requires_grad(model_actor, False)\n",
    "  requires_grad(model_critic, True)\n",
    "  \n",
    "  # 计算values和targets\n",
    "  value = model_critic(state)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    target = model_critic_delay(next_state)\n",
    "  target = target * 0.99 * (1 - over) + reward\n",
    "  \n",
    "  # 时序差分： tdloss\n",
    "  loss = torch.nn.functional.mse_loss(value, target)\n",
    "  \n",
    "  loss.backward()\n",
    "  optimizer_critic.step()\n",
    "  optimizer_critic.zero_grad()\n",
    "  \n",
    "  return value.detach()\n",
    "\n",
    "value = train_critic(state, reward, next_state, over)\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022671669721603394"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练actor\n",
    "def train_actor(state, action, value):\n",
    "  requires_grad(model_actor, True)\n",
    "  requires_grad(model_critic, False)\n",
    "  \n",
    "  # 重新计算动作概率\n",
    "  prob = model_actor(state)\n",
    "  prob = prob.gather(dim=1, index=action)\n",
    "  \n",
    "  # 根据策略梯度算法发的导函数\n",
    "  # 函数中的Q(state, action), 用critic模型估计\n",
    "  prob = (prob + 1e-8).log() * value\n",
    "  loss = -prob.mean()\n",
    "  \n",
    "  loss.backward()\n",
    "  optimizer_actor.step()\n",
    "  optimizer_actor.zero_grad()\n",
    "  \n",
    "  return loss.item()\n",
    "\n",
    "train_actor(state, action, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -6.459356784820557 -976.3\n",
      "100 -130.2356719970703 -891.9\n",
      "200 -29.019628524780273 200.0\n",
      "300 -12.627197265625 200.0\n",
      "400 -87.03160858154297 200.0\n",
      "500 -35.234317779541016 200.0\n",
      "600 -7.990650177001953 200.0\n",
      "700 -1.7405095100402832 200.0\n",
      "800 -0.7395690083503723 200.0\n",
      "900 -0.19511210918426514 200.0\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train():\n",
    "\tmodel_actor.train()\n",
    "\tmodel_critic.train()\n",
    "\n",
    "\t# 共更新N轮数据\n",
    "\tfor epoch in range(1000):\n",
    "\t\t# 一个epoch玩N步\n",
    "\t\tsteps = 0\n",
    "\t\twhile steps < 200:\n",
    "\t\t\t# 玩一局，得到数据\n",
    "\t\t\tstate, action, reward, next_state, over, _ = play()\n",
    "\t\t\tsteps += len(state)\n",
    "\n",
    "\t\t\t# 训练两个模型\n",
    "\t\t\tvalue = train_critic(state, reward, next_state, over)\n",
    "\t\t\tloss = train_actor(state, action, value)\n",
    "  \n",
    "\t\t# 复制参数\n",
    "\t\tfor param, param_delay in zip(model_critic.parameters(),\n",
    "                                model_critic_delay.parameters()):\n",
    "\t\t\tvalue = param_delay.data * 0.7 + param.data * 0.3\n",
    "\t\t\tparam_delay.data.copy_(value)\n",
    "  \n",
    "\t\tif epoch % 100 == 0:\n",
    "\t\t\ttest_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "\t\t\tprint(epoch, loss, test_result)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
