{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC and A2C: Advanced Actor-Critic (A2C) algorithm\n",
    "\n",
    "其实就是AC去基线的算法\n",
    "\n",
    "AC估计$Q(s, a)$的critic模型没有去基线，用target-value产生基线\n",
    "\n",
    "“换个角度来想这个问题,target是根据next_state估计出来的,value是根据state估计出来的\n",
    "\n",
    "所以两者的差值可以视为action好坏的衡量,这可以作为actor模型训练的依据”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# 定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "  \n",
    "  def __init__(self):\n",
    "    env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "    super().__init__(env)\n",
    "    self.env = env\n",
    "    self.step_n = 0\n",
    "    \n",
    "  def reset(self):\n",
    "    state, _ = self.env.reset()\n",
    "    self.step_n = 0\n",
    "    return state\n",
    "  \n",
    "  def step(self, action):\n",
    "    state, reward, terminated, truncated, info = self.env.step(action)\n",
    "    over = terminated or truncated\n",
    "\n",
    "    #限制最大步数\n",
    "    self.step_n += 1\n",
    "    if self.step_n >= 200:\n",
    "        over = True\n",
    "    \n",
    "    #没坚持到最后,扣分\n",
    "    if over and self.step_n < 200:\n",
    "        reward = -1000\n",
    "\n",
    "    return state, reward, over\n",
    "  \n",
    "  # 打印游戏图像\n",
    "  def show(self):\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(self.env.render())\n",
    "    plt.show()\n",
    "    \n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "env.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "   (5): Softmax(dim=1)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=64, out_features=1, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\t\n",
    "# 演员模型：计算动作概率\n",
    "model_actor = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 2),\n",
    "\ttorch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "# 评委模型：计算每个动作价值\n",
    "model_critic = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(4, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 64),\n",
    "\ttorch.nn.ReLU(),\n",
    "\ttorch.nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model_critic_delay.load_state_dict(model_critic.state_dict())\n",
    "\n",
    "model_actor, model_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fanyu\\AppData\\Local\\Temp\\ipykernel_45144\\195736856.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  state = torch.FloatTensor(state).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-986.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "\tstate = []\n",
    "\taction = []\n",
    "\treward = []\n",
    "\tnext_state = []\n",
    "\tover = []\n",
    "\n",
    "\ts = env.reset()\n",
    "\to = False\n",
    "\twhile not o:\n",
    "\t\t# 根据环境采样\n",
    "\t\tprob = model_actor(torch.FloatTensor(s).reshape(1, 4))[0].tolist()\n",
    "\t\ta = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\t\t\n",
    "\t\tns, r, o = env.step(a)\n",
    "\n",
    "\t\tstate.append(s)\n",
    "\t\taction.append(a)\n",
    "\t\treward.append(r)\n",
    "\t\tnext_state.append(ns)\n",
    "\t\tover.append(o)\n",
    "  \n",
    "\t\ts = ns\n",
    "\n",
    "\t\tif show:\n",
    "\t\t\tdisplay.clear_output(wait=True)\n",
    "\t\t\tenv.show()\n",
    "  \n",
    "\tstate = torch.FloatTensor(state).reshape(-1, 4)\n",
    "\taction = torch.LongTensor(action).reshape(-1, 1)\n",
    "\treward = torch.FloatTensor(reward).reshape(-1, 1)\n",
    "\tnext_state = torch.FloatTensor(next_state).reshape(-1, 4)\n",
    "\tover = torch.LongTensor(over).reshape(-1, 1)\n",
    "\n",
    "\treturn state, action, reward, next_state, over, reward.sum().item()\n",
    "\n",
    "state, action, reward, next_state, over, reward_sum = play()\n",
    "\n",
    "reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_actor = torch.optim.Adam(model_actor.parameters(), lr=4e-3)\n",
    "optimizer_critic = torch.optim.Adam(model_critic.parameters(), lr=4e-2)\n",
    "\n",
    "def requires_grad(model, value):\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad_(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# critic 模型训练\n",
    "def train_critic(state, reward, next_state, over):\n",
    "  requires_grad(model_actor, False)\n",
    "  requires_grad(model_critic, True)\n",
    "  \n",
    "  # 计算values和targets\n",
    "  value = model_critic(state)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    target = model_critic_delay(next_state)\n",
    "  target = target * 0.99 * (1 - over) + reward\n",
    "  \n",
    "  # 时序差分： tdloss\n",
    "  loss = torch.nn.functional.mse_loss(value, target)\n",
    "  \n",
    "  loss.backward()\n",
    "  optimizer_critic.step()\n",
    "  optimizer_critic.zero_grad()\n",
    "  \n",
    "  # 去基线\n",
    "  return (target - value).detach() # code change here\n",
    "\n",
    "value = train_critic(state, reward, next_state, over)\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-41.16533660888672"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练actor\n",
    "def train_actor(state, action, value):\n",
    "  requires_grad(model_actor, True)\n",
    "  requires_grad(model_critic, False)\n",
    "  \n",
    "  # 重新计算动作概率\n",
    "  prob = model_actor(state)\n",
    "  prob = prob.gather(dim=1, index=action)\n",
    "  \n",
    "  # 根据策略梯度算法发的导函数\n",
    "  # 函数中的Q(state, action), 用critic模型估计\n",
    "  prob = (prob + 1e-8).log() * value\n",
    "  loss = -prob.mean()\n",
    "  \n",
    "  loss.backward()\n",
    "  optimizer_actor.step()\n",
    "  optimizer_actor.zero_grad()\n",
    "  \n",
    "  return loss.item()\n",
    "\n",
    "train_actor(state, action, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.257709503173828 -982.3\n",
      "100 -0.3256535828113556 -3.2\n",
      "200 -1.7218737602233887 149.75\n",
      "300 0.21917232871055603 200.0\n",
      "400 0.02079101651906967 200.0\n",
      "500 0.0702286809682846 200.0\n",
      "600 -0.06104029342532158 200.0\n",
      "700 0.016140108928084373 200.0\n",
      "800 -1.173439621925354 200.0\n",
      "900 0.24530361592769623 200.0\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train():\n",
    "\tmodel_actor.train()\n",
    "\tmodel_critic.train()\n",
    "\n",
    "\t# 共更新N轮数据\n",
    "\tfor epoch in range(1000):\n",
    "\t\t# 一个epoch玩N步\n",
    "\t\tsteps = 0\n",
    "\t\twhile steps < 200:\n",
    "\t\t\t# 玩一局，得到数据\n",
    "\t\t\tstate, action, reward, next_state, over, _ = play()\n",
    "\t\t\tsteps += len(state)\n",
    "\n",
    "\t\t\t# 训练两个模型\n",
    "\t\t\tvalue = train_critic(state, reward, next_state, over)\n",
    "\t\t\tloss = train_actor(state, action, value)\n",
    "  \n",
    "\t\t# 复制参数\n",
    "\t\tfor param, param_delay in zip(model_critic.parameters(),\n",
    "                                model_critic_delay.parameters()):\n",
    "\t\t\tvalue = param_delay.data * 0.7 + param.data * 0.3\n",
    "\t\t\tparam_delay.data.copy_(value)\n",
    "  \n",
    "\t\tif epoch % 100 == 0:\n",
    "\t\t\ttest_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "\t\t\tprint(epoch, loss, test_result)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
