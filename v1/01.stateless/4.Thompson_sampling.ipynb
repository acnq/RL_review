{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateless Problem: Thompson Sampling\n",
    "\n",
    "汤普森采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemma: $\\beta$-distribution\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{B}(x; \\alpha, \\beta) &= C x^{\\alpha - 1} (1 - x)^{\\beta - 1} \\\\ \n",
    "&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha - 1} (1 - x)^{\\beta - 1} \\\\ \n",
    "&= \\frac1{\\Beta(\\alpha, \\beta)}x^{\\alpha - 1} (1 - x)^{\\beta - 1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\Gamma$ is Euler $\\Gamma$-funct:\n",
    "$$\n",
    "\\Gamma(x) = \\int_0^{+\\infin}t^{x - 1} e^{-t}dt(x > 0)\n",
    "$$\n",
    "if $x \\in N^+$, $\\Gamma(x) = x!$\n",
    "\n",
    "for $\\beta$ dist, $\\mathbb{E}(\\mathcal{B}) = \\frac{\\alpha}{\\alpha + \\beta}$, $\\mathbb{Var}(\\mathcal{B}) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.74421478, 0.26813075, 0.92777303, 0.5701738 , 0.37258173,\n",
       "        0.22315075, 0.38718998, 0.79308439, 0.72092343, 0.6306549 ]),\n",
       " [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 每个老虎机中奖概率均匀分布, 共10个\n",
    "probs = np.random.uniform(size=10)\n",
    "\n",
    "# 记录每个老虎机的返回值\n",
    "rewards = [[1] for _ in range(10)]\n",
    "\n",
    "probs, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数字小时，beta分布有很大随机性\n",
      "0.9133636940271159\n",
      "0.728337316337896\n",
      "0.642989119991121\n",
      "0.963628999183373\n",
      "0.3425361414062037\n",
      "数字大时，beta分布逐渐稳定\n",
      "0.5023018584560439\n",
      "0.49988173809382147\n",
      "0.49816430260921796\n",
      "0.49808291204244937\n",
      "0.499978411763636\n"
     ]
    }
   ],
   "source": [
    "## beta dist test\n",
    "print('数字小时，beta分布有很大随机性')\n",
    "for _ in range(5):\n",
    "  print(np.random.beta(1, 1))\n",
    "  \n",
    "print('数字大时，beta分布逐渐稳定')\n",
    "for _ in range(5):\n",
    "  print(np.random.beta(1e5, 1e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 概率递减的贪婪算法\n",
    "def choose_one():\n",
    "  # modified code here\n",
    "  # 求出得奖次数\n",
    "  count_1 = [sum(i) + 1 for i in rewards]\n",
    "  \n",
    "  # 求出无奖次数\n",
    "  count_0 = [sum(1 - np.array(i)) + 1 for i in rewards]\n",
    "  \n",
    "  # 根据以上两个参数计算奖励分布，近似中奖概率\n",
    "  beta = np.random.beta(count_1, count_0)\n",
    "  \n",
    "  return beta.argmax()\n",
    "\n",
    "  # modified code end\n",
    "\n",
    "choose_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1, 0], [1], [1], [1], [1], [1], [1], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_and_play():\n",
    "  i = choose_one()\n",
    "  \n",
    "  # act\n",
    "  reward = 0\n",
    "  if random.random() < probs[i]:\n",
    "    reward = 1\n",
    "    \n",
    "  # 记录结果\n",
    "  rewards[i].append(reward)\n",
    "  \n",
    "try_and_play()\n",
    "\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4638.865153582355, 4612)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result():\n",
    "  # 玩 N 次\n",
    "  for _ in range(5000):\n",
    "    try_and_play()\n",
    "    \n",
    "  # 期望的最好结果\n",
    "  target = probs.max() * 5000\n",
    "  \n",
    "  # 实际结果\n",
    "  result = sum([sum(i) for i in rewards])\n",
    "  \n",
    "  return target, result\n",
    "\n",
    "get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
